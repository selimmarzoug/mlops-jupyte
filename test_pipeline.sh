#!/bin/bash

# Script de test local du pipeline MLOps
# ======================================

echo "======================================================================"
echo "üöÄ TEST LOCAL DU PIPELINE MLOPS"
echo "======================================================================"

# Couleurs
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m' # No Color

# Fonction pour afficher les √©tapes
step() {
    echo ""
    echo "${YELLOW}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${NC}"
    echo "${YELLOW}$1${NC}"
    echo "${YELLOW}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${NC}"
}

success() {
    echo "${GREEN}‚úÖ $1${NC}"
}

error() {
    echo "${RED}‚ùå $1${NC}"
}

# V√©rifier l'environnement
step "√âTAPE 1: V√©rification de l'environnement"

if [ ! -d ".venv" ]; then
    error "Virtual environment non trouv√©"
    echo "Cr√©ez-le avec: python -m venv .venv"
    exit 1
fi
success "Virtual environment trouv√©"

if [ ! -f "data/googleplaystore_clean.csv" ]; then
    error "Fichier de donn√©es non trouv√©"
    echo "Copiez vos donn√©es vers: data/googleplaystore_clean.csv"
    exit 1
fi
success "Donn√©es trouv√©es"

# Activer l'environnement virtuel
source .venv/bin/activate 2>/dev/null || source .venv/Scripts/activate 2>/dev/null

# D√©marrer MLflow
step "√âTAPE 2: D√©marrage de MLflow"

echo "D√©marrage du serveur MLflow..."
mlflow server \
    --backend-store-uri sqlite:///mlflow.db \
    --default-artifact-root ./mlflow/artifacts \
    --host 0.0.0.0 \
    --port 5000 &
MLFLOW_PID=$!

sleep 5
success "MLflow d√©marr√© (PID: $MLFLOW_PID)"
echo "   Interface: http://localhost:5000"

export MLFLOW_TRACKING_URI=http://localhost:5000

# Test 1: V√©rifier les nouvelles donn√©es
step "√âTAPE 3: V√©rification des nouvelles donn√©es"

python src/check_new_data.py
if [ $? -eq 0 ]; then
    success "V√©rification des donn√©es OK"
else
    error "Erreur lors de la v√©rification"
    kill $MLFLOW_PID
    exit 1
fi

HAS_NEW_DATA=$(cat /tmp/has_new_data.txt)
NEW_DATA_COUNT=$(cat /tmp/new_data_count.txt)

echo "   Nouvelles donn√©es: $HAS_NEW_DATA"
echo "   Nombre: $NEW_DATA_COUNT"

# Test 2: Entra√Ænement
step "√âTAPE 4: Entra√Ænement du mod√®le"

python src/train_pipeline.py
if [ $? -eq 0 ]; then
    success "Entra√Ænement r√©ussi"
else
    error "Erreur lors de l'entra√Ænement"
    kill $MLFLOW_PID
    exit 1
fi

MODEL_VERSION=$(cat /tmp/model_version.txt)
ACCURACY=$(cat /tmp/accuracy.txt)
IMPROVEMENT=$(cat /tmp/improvement.txt)

echo "   Version: $MODEL_VERSION"
echo "   Accuracy: $ACCURACY"
echo "   Am√©lioration: $IMPROVEMENT"

# Test 3: D√©cision de d√©ploiement
step "√âTAPE 5: D√©cision de d√©ploiement"

python src/deployment_decision.py
if [ $? -eq 0 ]; then
    success "D√©cision prise"
else
    error "Erreur lors de la d√©cision"
    kill $MLFLOW_PID
    exit 1
fi

SHOULD_DEPLOY=$(cat /tmp/should_deploy.txt)
echo "   D√©ploiement approuv√©: $SHOULD_DEPLOY"

# Test 4: D√©ploiement (si approuv√©)
if [ "$SHOULD_DEPLOY" = "true" ]; then
    step "√âTAPE 6: D√©ploiement en staging"
    
    python src/deploy.py --environment staging
    if [ $? -eq 0 ]; then
        success "D√©ploiement staging OK"
    else
        error "Erreur d√©ploiement staging"
        kill $MLFLOW_PID
        exit 1
    fi
    
    step "√âTAPE 7: Tests de d√©ploiement"
    
    python src/test_deployment.py --environment staging
    if [ $? -eq 0 ]; then
        success "Tests r√©ussis"
    else
        error "Tests √©chou√©s"
        kill $MLFLOW_PID
        exit 1
    fi
    
    step "√âTAPE 8: D√©ploiement canary (5%)"
    
    python src/deploy.py --environment production --canary 0.05
    success "D√©ploiement canary OK"
    
    step "√âTAPE 9: Monitoring canary"
    
    python src/monitor_canary.py --duration 5
    success "Monitoring OK"
    
    step "√âTAPE 10: D√©ploiement production complet"
    
    python src/deploy.py --environment production --canary 1.0
    success "D√©ploiement production OK"
    
    step "√âTAPE 11: Notification"
    
    python src/notify.py \
        --version "$MODEL_VERSION" \
        --accuracy "$ACCURACY" \
        --improvement "$IMPROVEMENT"
    success "Notification envoy√©e"
else
    echo ""
    echo "${YELLOW}‚ö†Ô∏è  D√©ploiement non approuv√© - Score insuffisant${NC}"
fi

# Test 5: G√©n√©ration du rapport
step "√âTAPE 12: G√©n√©ration du rapport"

python src/generate_report.py
if [ $? -eq 0 ]; then
    success "Rapport g√©n√©r√©"
    echo "   Voir: reports/"
else
    error "Erreur g√©n√©ration rapport"
fi

# Nettoyer
step "NETTOYAGE"

kill $MLFLOW_PID
success "MLflow arr√™t√©"

# R√©sum√©
step "R√âSUM√â DES TESTS"

echo ""
echo "üéØ Pipeline test√© avec succ√®s!"
echo ""
echo "üìä R√©sultats:"
echo "   ‚Ä¢ Nouvelles donn√©es: $NEW_DATA_COUNT"
echo "   ‚Ä¢ Mod√®le version: $MODEL_VERSION"
echo "   ‚Ä¢ Accuracy: $ACCURACY"
echo "   ‚Ä¢ Am√©lioration: $IMPROVEMENT"
echo "   ‚Ä¢ D√©ploiement: $SHOULD_DEPLOY"
echo ""
echo "üìÅ Fichiers g√©n√©r√©s:"
echo "   ‚Ä¢ models/candidate_model.pkl"
echo "   ‚Ä¢ reports/*.json"
echo "   ‚Ä¢ logs/deployment.log"
echo ""
echo "üåê Pour voir dans MLflow:"
echo "   1. mlflow server --backend-store-uri sqlite:///mlflow.db --host 0.0.0.0 --port 5000"
echo "   2. Ouvrir: http://localhost:5000"
echo ""
echo "======================================================================"
echo "‚úÖ TOUS LES TESTS ONT R√âUSSI!"
echo "======================================================================"
