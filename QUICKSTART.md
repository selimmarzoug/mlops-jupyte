# ğŸš€ Quick Start - Pipeline MLOps

Guide rapide pour dÃ©marrer le pipeline en 5 minutes!

## âš¡ DÃ©marrage Rapide

### 1. Installation (2 minutes)

```bash
# Cloner ou se placer dans le projet
cd mlops-jupyter

# Installer les dÃ©pendances
pip install -r requirements.txt

# VÃ©rifier l'installation
python --version  # Devrait Ãªtre >= 3.8
mlflow --version
```

### 2. Test Local (3 minutes)

```bash
# Lancer le test complet
./test_pipeline.sh

# Ou Ã©tape par Ã©tape:

# DÃ©marrer MLflow
mlflow server \
  --backend-store-uri sqlite:///mlflow.db \
  --default-artifact-root ./mlflow/artifacts \
  --host 0.0.0.0 \
  --port 5000 &

# Tester le pipeline
export MLFLOW_TRACKING_URI=http://localhost:5000
python src/check_new_data.py
python src/train_pipeline.py
python src/deployment_decision.py
python src/deploy.py --environment production
```

### 3. Push vers GitHub

```bash
# CrÃ©er le repo sur GitHub (via l'interface web)
# Puis:

git init
git add .
git commit -m "Initial commit: MLOps pipeline"
git branch -M main
git remote add origin https://github.com/VOTRE-USERNAME/mlops-jupyter.git
git push -u origin main
```

### 4. Activer GitHub Actions

1. Aller sur GitHub â†’ Votre repo
2. Cliquer sur l'onglet **Actions**
3. Cliquer sur **"I understand my workflows, go ahead and enable them"**
4. Le workflow `ml-pipeline.yml` est maintenant actif! ğŸ‰

### 5. DÃ©clencher le Pipeline

**Option A: Automatique** (quand vous ajoutez des donnÃ©es)
```bash
# Ajouter des donnÃ©es
echo "new_data" >> data/googleplaystore_clean.csv

# Commit et push
git add data/
git commit -m "feat: ajout de nouvelles applications"
git push origin main

# â†’ Pipeline se dÃ©clenche automatiquement!
```

**Option B: Manuel** (via GitHub UI)
1. Aller dans **Actions**
2. SÃ©lectionner **ML Pipeline**
3. Cliquer sur **Run workflow**
4. Choisir la branche `main`
5. Cliquer sur **Run workflow**

## ğŸ“Š Voir les RÃ©sultats

### GitHub Actions
- **URL**: `https://github.com/VOTRE-USERNAME/mlops-jupyter/actions`
- Voir les logs en temps rÃ©el
- TÃ©lÃ©charger les artifacts (modÃ¨les, rapports)

### MLflow UI
```bash
# En local
mlflow server --backend-store-uri sqlite:///mlflow.db --host 0.0.0.0 --port 5000

# Ouvrir: http://localhost:5000
```

### Fichiers GÃ©nÃ©rÃ©s
```
models/
â”œâ”€â”€ candidate_model.pkl          # Nouveau modÃ¨le
â”œâ”€â”€ production_model.pkl         # ModÃ¨le en production
â””â”€â”€ production_model_backup_*.pkl # Backups

reports/
â””â”€â”€ report_*.json                # Rapports de performance

logs/
â””â”€â”€ deployment.log               # Historique des dÃ©ploiements
```

## ğŸ”„ Workflow Quotidien

```bash
# 1. Matin: Ajouter des nouvelles donnÃ©es
cat new_apps.csv >> data/googleplaystore_clean.csv

# 2. Commit
git add data/
git commit -m "feat: donnÃ©es du $(date +%Y-%m-%d)"
git push

# 3. GitHub Actions se dÃ©clenche
# â†’ VÃ©rifie les donnÃ©es
# â†’ EntraÃ®ne si nÃ©cessaire
# â†’ DÃ©ploie automatiquement si amÃ©lioration

# 4. VÃ©rifier les rÃ©sultats
# â†’ GitHub Actions (logs)
# â†’ MLflow UI (mÃ©triques)
# â†’ Notifications (Slack/Email)
```

## ğŸ› ï¸ Commandes Utiles

```bash
# Tester le pipeline complet
./test_pipeline.sh

# Forcer un rÃ©entraÃ®nement
python src/train_pipeline.py

# DÃ©ployer manuellement
python src/deploy.py --environment production

# Rollback
python src/deploy.py --rollback

# Voir les logs
cat logs/deployment.log

# Nettoyer
rm -rf mlflow/artifacts/*
rm models/*.pkl
```

## ğŸ› DÃ©pannage

### ProblÃ¨me: MLflow ne dÃ©marre pas
```bash
# VÃ©rifier le port
lsof -i :5000
# ou
netstat -tuln | grep 5000

# Tuer le processus
kill -9 <PID>

# RedÃ©marrer
mlflow server --backend-store-uri sqlite:///mlflow.db --port 5000
```

### ProblÃ¨me: GitHub Actions Ã©choue
```bash
# VÃ©rifier les logs dans GitHub
# Actions â†’ Votre workflow â†’ Logs dÃ©taillÃ©s

# Tester localement d'abord
./test_pipeline.sh
```

### ProblÃ¨me: Pas de nouvelles donnÃ©es dÃ©tectÃ©es
```bash
# VÃ©rifier le seuil (100 apps par dÃ©faut)
# Modifier dans src/check_new_data.py:
threshold = 50  # Au lieu de 100

# Ou forcer le rÃ©entraÃ®nement
python src/train_pipeline.py
```

## ğŸ“š Documentation ComplÃ¨te

Voir [README_PIPELINE.md](README_PIPELINE.md) pour:
- Architecture dÃ©taillÃ©e
- Configuration avancÃ©e
- Monitoring et alertes
- Best practices

## ğŸ“ Prochaines Ã‰tapes

1. **Configurer les notifications**
   - Slack webhook dans `src/notify.py`
   - Email SMTP

2. **Monitoring avancÃ©**
   - Prometheus
   - Grafana
   - Evidently AI (data drift)

3. **Tests plus robustes**
   - Unit tests
   - Integration tests
   - A/B testing

4. **DÃ©ploiement cloud**
   - AWS SageMaker
   - Azure ML
   - Google Cloud AI Platform

## ğŸ’¬ Support

Des questions? CrÃ©ez une issue sur GitHub!

---

**Happy ML Engineering! ğŸš€**
