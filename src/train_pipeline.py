"""
Pipeline d'Entra√Ænement avec MLflow
===================================
Entra√Æne un nouveau mod√®le et le compare avec le mod√®le en production
"""

import pandas as pd
import numpy as np
import mlflow
import mlflow.sklearn
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report
import joblib
import os
from datetime import datetime

# Configuration MLflow
MLFLOW_TRACKING_URI = os.environ.get('MLFLOW_TRACKING_URI', 'http://localhost:5000')
mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)

def load_data():
    """Charge et pr√©pare les donn√©es"""
    print("üìä Chargement des donn√©es...")
    df = pd.read_csv('data/googleplaystore_clean.csv')
    
    # Ici, ajoutez votre logique de preprocessing
    # Pour la d√©mo, on cr√©e des features synth√©tiques
    X = df.select_dtypes(include=[np.number]).fillna(0)
    
    # Cr√©er une target si elle n'existe pas (exemple)
    if 'Rating' in df.columns:
        y = (df['Rating'] > 4.0).astype(int)
    else:
        # Fallback: target synth√©tique
        y = (X.iloc[:, 0] > X.iloc[:, 0].median()).astype(int)
    
    print(f"‚úÖ Donn√©es charg√©es: {len(df)} applications")
    print(f"   Features: {X.shape[1]}")
    print(f"   Distribution: {np.mean(y):.1%} succ√®s")
    
    return X, y

def train_model(X_train, y_train, X_test, y_test, experiment_name="google-playstore-ci-cd"):
    """Entra√Æne plusieurs mod√®les et s√©lectionne le meilleur"""
    
    mlflow.set_experiment(experiment_name)
    
    models = {
        'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),
        'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42)
    }
    
    best_model = None
    best_accuracy = 0
    best_metrics = {}
    
    print("\nüîß Entra√Ænement des mod√®les...")
    
    for model_name, model in models.items():
        with mlflow.start_run(run_name=f"{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"):
            # Entra√Ænement
            model.fit(X_train, y_train)
            
            # Pr√©dictions
            y_pred = model.predict(X_test)
            y_proba = model.predict_proba(X_test)[:, 1]
            
            # M√©triques
            accuracy = accuracy_score(y_test, y_pred)
            f1 = f1_score(y_test, y_pred)
            roc_auc = roc_auc_score(y_test, y_proba)
            
            # Log dans MLflow
            mlflow.log_param("model_type", model_name)
            mlflow.log_metric("accuracy", accuracy)
            mlflow.log_metric("f1_score", f1)
            mlflow.log_metric("roc_auc", roc_auc)
            
            # Log du mod√®le
            mlflow.sklearn.log_model(model, "model")
            
            print(f"\n{model_name}:")
            print(f"   Accuracy: {accuracy:.4f}")
            print(f"   F1-Score: {f1:.4f}")
            print(f"   ROC-AUC: {roc_auc:.4f}")
            
            # Garder le meilleur
            if accuracy > best_accuracy:
                best_accuracy = accuracy
                best_model = model
                best_metrics = {
                    'accuracy': accuracy,
                    'f1_score': f1,
                    'roc_auc': roc_auc,
                    'model_name': model_name
                }
    
    return best_model, best_metrics

def compare_with_production(new_metrics):
    """Compare le nouveau mod√®le avec celui en production"""
    
    print("\n‚öñÔ∏è  Comparaison avec le mod√®le en production...")
    
    prod_model_path = 'models/production_model.pkl'
    prod_metrics_path = 'models/production_metrics.txt'
    
    if not os.path.exists(prod_metrics_path):
        print("üÜï Pas de mod√®le en production - premier d√©ploiement")
        improvement = new_metrics['accuracy']
    else:
        with open(prod_metrics_path, 'r') as f:
            prod_accuracy = float(f.read().strip())
        
        improvement = new_metrics['accuracy'] - prod_accuracy
        
        print(f"Production: {prod_accuracy:.4f}")
        print(f"Nouveau:    {new_metrics['accuracy']:.4f}")
        print(f"Diff√©rence: {improvement:+.4f} ({(improvement/prod_accuracy)*100:+.2f}%)")
    
    return improvement

def main():
    """Pipeline principal"""
    
    print("="*60)
    print("üöÄ PIPELINE D'ENTRA√éNEMENT ML")
    print("="*60)
    
    # Charger les donn√©es
    X, y = load_data()
    
    # Split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # Entra√Æner
    best_model, best_metrics = train_model(X_train, y_train, X_test, y_test)
    
    # Comparer
    improvement = compare_with_production(best_metrics)
    
    # Sauvegarder le mod√®le
    os.makedirs('models', exist_ok=True)
    model_path = 'models/candidate_model.pkl'
    joblib.dump(best_model, model_path)
    
    # Sauvegarder les m√©triques
    with open('/tmp/model_version.txt', 'w') as f:
        f.write(f"v{datetime.now().strftime('%Y%m%d_%H%M%S')}")
    
    with open('/tmp/accuracy.txt', 'w') as f:
        f.write(f"{best_metrics['accuracy']:.4f}")
    
    with open('/tmp/improvement.txt', 'w') as f:
        f.write(f"{improvement:.4f}")
    
    # Mettre √† jour le compteur de donn√©es
    df = pd.read_csv('data/googleplaystore_clean.csv')
    with open('models/last_training_date.txt', 'w') as f:
        f.write(str(len(df)))
    
    print("\n‚úÖ Entra√Ænement termin√© avec succ√®s!")
    print(f"üì¶ Mod√®le sauvegard√©: {model_path}")
    print("="*60)

if __name__ == '__main__':
    main()
