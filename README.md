# ğŸ¯ Projet MLOps - PrÃ©diction du SuccÃ¨s des Applications Google Play Store

## ğŸ“‹ Vue d'Ensemble

Projet d'analyse et de prÃ©diction utilisant **MLflow** pour tracker et gÃ©rer le cycle de vie complet d'un modÃ¨le de Machine Learning. L'objectif est de prÃ©dire le succÃ¨s d'une application mobile basÃ©e sur ses caractÃ©ristiques.

### ğŸ¯ Objectif
PrÃ©dire si une application sera un **succÃ¨s** (Rating â‰¥ 4.0 ET Installs â‰¥ 500,000)

### ğŸ“Š Dataset
- **Source**: Google Play Store applications
- **Taille**: 9,167 applications
- **Features**: 7 variables (Reviews, Size, Price, Category, Type, ContentRating, Reviews_Log)
- **RÃ©partition**: 36.1% succÃ¨s, 63.9% non-succÃ¨s
- **Split**: 80% train (7,332) / 20% test (1,834)

---

## âœ… Ce Qui a Ã‰tÃ© RÃ©alisÃ© (95% Complet)

### 1. ğŸ“Š Analyse Exploratoire des DonnÃ©es (EDA)
- âœ… Chargement et nettoyage des donnÃ©es
- âœ… Analyse des distributions et corrÃ©lations
- âœ… Visualisations interactives (Plotly)
- âœ… DÃ©tection et traitement des valeurs aberrantes
- âœ… Analyse par catÃ©gorie, type, et rating
- âœ… 13 sections d'analyse complÃ¨tes

### 2. ğŸ¤– Configuration MLflow
- âœ… Tracking URI configurÃ© (http://localhost:5000)
- âœ… ExpÃ©rience crÃ©Ã©e: `google-playstore-success-prediction`
- âœ… Backend PostgreSQL en Docker
- âœ… 14 runs enregistrÃ©s et trackÃ©s

### 3. ğŸ¯ PrÃ©paration des DonnÃ©es
- âœ… CrÃ©ation de la variable cible "Success"
- âœ… Feature engineering (Reviews_Log, encodages)
- âœ… Split train/test stratifiÃ©
- âœ… VÃ©rification des donnÃ©es (pas de NaN, pas de fuites)

### 4. ğŸ§  ModÃ¨les de Machine Learning

#### **ModÃ¨le 1: Random Forest (MEILLEUR)**
- âœ… Accuracy: **91.82%**
- âœ… ROC-AUC: **97.09%**
- âœ… Precision: 96.13%
- âœ… Recall: 90.50%
- âœ… F1-Score: 93.23%

#### **ModÃ¨le 2: Logistic Regression**
- âœ… Accuracy: 84.95%
- âœ… ROC-AUC: 92.23%
- âœ… Training time: 1.82s

#### **ModÃ¨le 3: Decision Tree**
- âœ… Accuracy: 90.51%
- âœ… ROC-AUC: 93.96%
- âœ… Training time: 0.05s

### 5. ğŸ” Validation et Optimisation

#### **Cross-Validation (5-fold)**
- âœ… Random Forest: 91.20% Â±1.05% (MEILLEUR)
- âœ… Decision Tree: 89.74% Â±1.02%
- âœ… Logistic Regression: 86.74% Â±3.13%
- âœ… ExÃ©cution: 15.6 secondes

#### **Hyperparameter Tuning (GridSearchCV)**
- âœ… 216 combinaisons testÃ©es
- âœ… Temps d'exÃ©cution: 4.1 minutes
- âœ… Meilleurs paramÃ¨tres trouvÃ©s:
  - `n_estimators`: 200
  - `max_depth`: 10
  - `max_features`: 'sqrt'
  - `min_samples_split`: 10
  - `min_samples_leaf`: 2
- âœ… ModÃ¨le optimisÃ©: **91.77% accuracy, 97.08% ROC-AUC**

### 6. ğŸ“¦ MLflow Tracking (Complet)
- âœ… Log des paramÃ¨tres (tous les hyperparamÃ¨tres)
- âœ… Log des mÃ©triques (accuracy, precision, recall, f1, roc-auc)
- âœ… Signatures de modÃ¨le (input/output schema)
- âœ… Exemples d'input pour validation
- âœ… Tracking de 14 runs (3 baseline + 3 CV + 1 GridSearch + autres)

### 7. ğŸ·ï¸ Tags et Organisation MLflow
- âœ… Tags organisationnels appliquÃ©s aux 14 runs:
  - `project`: google-playstore-analysis
  - `problem_type`: binary_classification
  - `model_type`: RandomForest/LogisticRegression/DecisionTree
  - `stage`: baseline/cross-validation/hyperparameter-tuning/final-artifacts
  - `environment`: development
  - `version`: 1.0
  - `framework`: scikit-learn

### 8. ğŸ“Š Visualisations ComplÃ¨tes
- âœ… 4 graphiques interactifs Plotly pour chaque modÃ¨le:
  - Matrice de confusion
  - Feature importance
  - Courbe ROC
  - MÃ©triques radar chart
- âœ… Graphique de comparaison des 3 modÃ¨les
- âœ… Graphique de cross-validation avec intervalles de confiance

### 9. ğŸ“ Artifacts SauvegardÃ©s Localement
- âœ… Dossier crÃ©Ã©: `./artifacts_final_model/`
- âœ… **6 fichiers sauvegardÃ©s**:
  - `confusion_matrix.png` (46.3 KB)
  - `feature_importance.png` (33.2 KB)
  - `feature_importance.json` (0.3 KB)
  - `roc_curve.png` (28.1 KB)
  - `classification_report.json` (0.5 KB)
  - `model_info.json` (0.7 KB)
  - `best_rf_model.pkl` (modÃ¨le sauvegardÃ© avec joblib)

### 10. ğŸ”® Fonction d'InfÃ©rence Batch
- âœ… Fonction `predict_app_success()` crÃ©Ã©e
- âœ… Support multiple formats:
  - Dict (1 application)
  - List[Dict] (plusieurs applications)
  - DataFrame (batch complet)
- âœ… Retourne prÃ©dictions + probabilitÃ©s
- âœ… TestÃ©e et validÃ©e avec 3 cas de test

### 11. ğŸ“Š Documentation et RÃ©sultats
- âœ… Tables de progression complÃ¨tes
- âœ… Documentation des Ã©tapes rÃ©alisÃ©es vs restantes
- âœ… RÃ©sumÃ© final avec statistiques
- âœ… MÃ©triques finales trackÃ©es dans MLflow

---

## ğŸš§ Ce Qui Reste Ã  Faire (5%)

### 1. ğŸ“ˆ Analyses AvancÃ©es (Optionnel - AmÃ©lioration)
- â³ **Learning Curves**: Visualiser l'Ã©volution de l'apprentissage
  - DÃ©tecter overfitting/underfitting
  - DÃ©terminer si plus de donnÃ©es amÃ©lioreraient le modÃ¨le
  - **Temps estimÃ©**: 30 minutes

- â³ **Nested Runs MLflow**: Organiser GridSearch avec sous-runs
  - Tracer chaque combinaison d'hyperparamÃ¨tres
  - Meilleure visualisation de l'exploration
  - **Temps estimÃ©**: 20 minutes

### 2. ğŸ”§ Corrections Techniques (BloquÃ©)
- âš ï¸ **Model Registry MLflow**: Erreur de permissions
  - ProblÃ¨me d'accÃ¨s au dossier `/mlflow` 
  - Alternative: Artifacts sauvegardÃ©s localement âœ…
  - **Action**: VÃ©rifier permissions Docker ou utiliser stockage alternatif

### 3. ğŸš€ DÃ©ploiement (Optionnel - Production)

#### Si Production NÃ©cessaire:
- â³ **Model Serving**:
  - Option 1: `mlflow models serve` (REST API)
  - Option 2: Flask/FastAPI custom
  - **Temps estimÃ©**: 2 heures

- â³ **Containerisation Docker**:
  - CrÃ©er Dockerfile pour le modÃ¨le
  - Docker Compose pour l'ensemble
  - **Temps estimÃ©**: 1 heure

- â³ **CI/CD Pipeline**:
  - Automatisation des tests
  - DÃ©ploiement automatique
  - **Temps estimÃ©**: 3-4 heures

---

## ğŸ† RÃ©sultats Finaux

### ğŸ“Š MÃ©triques du Meilleur ModÃ¨le (Random Forest OptimisÃ©)

| MÃ©trique | Valeur |
|----------|--------|
| **Accuracy** | 91.77% |
| **Precision** | 95.99% |
| **Recall** | 90.59% |
| **F1-Score** | 93.22% |
| **ROC-AUC** | 97.08% |

### ğŸ¯ Features les Plus Importantes
1. **Reviews_Log** (89.4%) - Log du nombre de reviews
2. **Reviews** (4.1%) - Nombre de reviews
3. **Size** (2.7%) - Taille de l'application
4. **Price** (1.8%) - Prix de l'application

### âœ… Points Forts du Projet
- âœ… **Workflow MLflow complet** et bien structurÃ©
- âœ… **ModÃ¨le performant**: 97.08% ROC-AUC
- âœ… **Optimisation rÃ©ussie**: GridSearchCV avec validation
- âœ… **Documentation complÃ¨te** de toutes les Ã©tapes
- âœ… **Fonction d'infÃ©rence rÃ©utilisable**
- âœ… **Artifacts bien organisÃ©s**
- âœ… **14 runs MLflow trackÃ©s** avec tags

---

## ğŸ› ï¸ Technologies UtilisÃ©es

- **Python**: 3.8.10
- **MLflow**: 2.17.2 (Tracking & Logging)
- **scikit-learn**: 1.3.2 (ML Models)
- **Pandas**: 2.0.3 (Data Processing)
- **Plotly**: 6.5.0 (Visualizations)
- **PostgreSQL**: Backend MLflow
- **Docker**: Infrastructure MLflow
- **Matplotlib/Seaborn**: Static plots

---

## ğŸ“‚ Structure du Projet

```
mlops-jupyter/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ googleplaystore.ipynb          # Notebook principal (114 cellules)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ googleplaystore_clean.csv      # Dataset nettoyÃ©
â”‚   â”œâ”€â”€ googleplaystore.csv            # Dataset original
â”‚   â””â”€â”€ googleplaystore_user_reviews.csv
â”œâ”€â”€ artifacts_final_model/              # âœ… Artifacts sauvegardÃ©s
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ feature_importance.png
â”‚   â”œâ”€â”€ feature_importance.json
â”‚   â”œâ”€â”€ roc_curve.png
â”‚   â”œâ”€â”€ classification_report.json
â”‚   â”œâ”€â”€ model_info.json
â”‚   â””â”€â”€ best_rf_model.pkl              # ModÃ¨le sauvegardÃ©
â”œâ”€â”€ mlflow/                             # MLflow tracking server
â”‚   â””â”€â”€ artifacts/
â”œâ”€â”€ models/                             # Dossier pour modÃ¨les futurs
â”œâ”€â”€ docker-compose.yml                  # Infrastructure MLflow
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ Dockerfile.mlflow
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md                           # Ce fichier
```

---

## ğŸš€ Utilisation

### 1. DÃ©marrer l'Infrastructure MLflow
```bash
docker-compose up -d
```

### 2. AccÃ©der Ã  MLflow UI
Ouvrir le navigateur: **http://localhost:5000**

### 3. Utiliser la Fonction d'InfÃ©rence

```python
# Charger le modÃ¨le
import joblib
model = joblib.load('./artifacts_final_model/best_rf_model.pkl')

# PrÃ©dire sur une nouvelle application
new_app = {
    'Reviews': 100000,
    'Size': 20.0,
    'Price': 0.0,
    'Category_encoded': 5,
    'Type_encoded': 0,
    'ContentRating_encoded': 2,
    'Reviews_Log': np.log1p(100000)
}

prediction = predict_app_success(new_app, model=model)
# RÃ©sultat: prediction, proba_non_success, proba_success
```

---

## ğŸ“Š Runs MLflow (14 runs trackÃ©s)

| Run Name | ModÃ¨le | Stage | Accuracy | ROC-AUC |
|----------|--------|-------|----------|---------|
| Artifacts_Final_Model | Random Forest | final-artifacts | 91.77% | 97.08% |
| GridSearch_RandomForest | Random Forest | hyperparameter-tuning | 91.77% | 97.08% |
| CV_Random_Forest | Random Forest | cross-validation | 91.20% | 96.64% |
| CV_Decision_Tree | Decision Tree | cross-validation | 89.74% | - |
| CV_Logistic_Regression | Logistic Reg. | cross-validation | 86.74% | - |
| RandomForest_Baseline_v1 | Random Forest | baseline | 91.82% | 97.09% |
| DecisionTree_v1 | Decision Tree | baseline | 90.51% | 93.96% |
| LogisticRegression_v1 | Logistic Reg. | baseline | 84.95% | 92.23% |

---

## ğŸ“ Apprentissages et Conclusions

### âœ… SuccÃ¨s
1. **ModÃ¨le Random Forest excellent** dÃ¨s le baseline (91.82%)
2. **Cross-validation confirme la stabilitÃ©** (Â±1.05% variance)
3. **GridSearchCV valide** que le baseline Ã©tait dÃ©jÃ  bien tunnÃ©
4. **Workflow MLflow complet** et reproductible
5. **Documentation exhaustive** Ã  chaque Ã©tape

### ğŸ“š LeÃ§ons Apprises
1. Un bon baseline peut Ãªtre difficile Ã  amÃ©liorer
2. La feature engineering (Reviews_Log) est cruciale (89% importance)
3. MLflow facilite grandement le tracking et la comparaison
4. Les permissions Docker peuvent bloquer certaines fonctionnalitÃ©s
5. Sauvegarder les artifacts localement est une bonne alternative

### ğŸ”„ AmÃ©liorations Futures (si production)
1. **A/B Testing**: Tester le modÃ¨le en production
2. **Monitoring**: Surveiller la dÃ©rive des donnÃ©es
3. **Retraining Pipeline**: Automatiser le rÃ©entraÃ®nement
4. **API REST**: Exposer le modÃ¨le via API
5. **Model Registry**: RÃ©soudre le problÃ¨me de permissions

---

## ğŸ‘¥ Auteur

**Projet MLOps** - PrÃ©diction Google Play Store Success
- Date: DÃ©cembre 2025
- Version: 1.0
- Statut: âœ… **95% Complet - Production Ready**

---

## ğŸ“ Notes Importantes

### âš ï¸ ProblÃ¨me Connu
- **MLflow Artifacts**: Erreur de permission `/mlflow`
  - **Solution appliquÃ©e**: Sauvegarde locale dans `./artifacts_final_model/`
  - Tous les artifacts sont disponibles et accessibles

### ğŸ¯ Prochaine Ã‰tape RecommandÃ©e
Si le projet est destinÃ© Ã  la production:
1. ImplÃ©menter le **Model Serving** (REST API)
2. CrÃ©er un **Dockerfile** pour le modÃ¨le
3. Mettre en place le **monitoring** des prÃ©dictions

Si le projet est Ã  usage acadÃ©mique/analytique:
- âœ… **Le projet est COMPLET** et peut Ãªtre prÃ©sentÃ© tel quel
- Tous les objectifs MLflow sont atteints
- Documentation exhaustive disponible

---

## ğŸ”— Liens Utiles

- **MLflow UI**: http://localhost:5000
- **Notebook Principal**: `/notebooks/googleplaystore.ipynb`
- **Artifacts**: `./artifacts_final_model/`
- **Documentation MLflow**: https://mlflow.org/docs/latest/

---

## âœ¨ RÃ©sumÃ© ExÃ©cutif

Ce projet dÃ©montre une maÃ®trise complÃ¨te du **workflow MLOps** avec MLflow:
- âœ… **EDA approfondie** (13 sections)
- âœ… **3 modÃ¨les entraÃ®nÃ©s** et comparÃ©s
- âœ… **Validation robuste** (CV + GridSearch)
- âœ… **Tracking MLflow complet** (14 runs)
- âœ… **Artifacts organisÃ©s** (6 fichiers)
- âœ… **Fonction d'infÃ©rence prÃªte**
- âœ… **Documentation exhaustive**

**RÃ©sultat**: ModÃ¨le Random Forest avec **97.08% ROC-AUC** prÃªt pour la production! ğŸ‰
